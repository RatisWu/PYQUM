# -*- coding: utf-8 -*-
"""ToolFunc.ipynb

Automatically generated by Colaboratory.

Original file is located at
		https://colab.research.google.com/drive/1cENx0sWVzgOvxoXwvxcrxvNQdAAANFUG
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# find the extreme value in 2D array
def extreme_2d(x):
	max_loc = []
	min_loc = []
	for i in range(x.shape[0]):
		ans_max = np.max(x[i])
		ans_min = np.min(x[i])
		max_loc.append(ans_max)
		min_loc.append(ans_min)
	return np.max(np.array(max_loc)),np.min(np.array(min_loc))

# 2D array normalize method
def normalize_2d(train):
	max ,min = extreme_2d(train)
	for i in range(train.shape[0]):
		for j in range(train.shape[1]):
			train[i][j] = (train[i][j] - min)/(max - min)
	return train

# define to simplfy freq obtaining
def find_freq(freq):
	freq_txt = []
	for i in range(freq.shape[0]):
		freq_txt.append([float(freq[i][0]),float(freq[i][freq.shape[1]-1])])
	freq_txt = np.array(freq_txt)
	return freq_txt

# define the method of input process
def input_process(file):
	dfs = []	
	data_arrays = []

	for i in range(1):				 #There are only 1 file
		read = pd.read_csv(file)
		if read.shape[0]%50 != 0:							
			dfs.append(pd.DataFrame(read[0:(read.shape[0]-(read.shape[0]%50))].drop(['exported by'], axis=1).values.astype(float))) #[0:(read.shape[0]-(read.shape[0]%len))] make the length be the 50 times
		else:
			dfs.append(pd.DataFrame(read[0:read.shape[0]].drop(['exported by'], axis=1).values.astype(float))) #freq,Amp,Uphase,I,Q
								
		temp = []					 # There are 3 arrays in the temp : [Freq, Amp, Pha]
		for j in range(3):
			temp.append(np.array(dfs[i][j]))


		data_arrays.append(np.array(temp))			

	datas = np.array(data_arrays)
	# cut the file for len = 50
	shift = [0,25]
	shifted = []
	for l in shift:
		seperated = []
		for i in range(datas.shape[0]):																 # with the freq range	"4~5 ,..."
			temp = []
			for j in range(datas.shape[1]):															 # with the label "freq,Amp,Pha" 
				temp_ = []																	 
				for k in range(0,datas.shape[2]-50-l,50):
						
					temp_.append(np.array(datas[i][j][k+l:k+l+50]))					# seperate with length = len 
				temp.append(temp_)

			seperated.append(temp)
		shifted.append(seperated)
	shifted = np.array(shifted)

# extract amplitude. phase, frequency
	amp = shifted[0][0][1]
	amp_shifted = shifted[1][0][1]
	pha = shifted[0][0][2]
	pha_shifted = shifted[1][0][2]
	freq = shifted[0][0][0]	
	freq_shifted = shifted[1][0][0]

	freq = find_freq(freq)
	freq_shifted = find_freq(freq_shifted)

	# normalize amp
	amp_norm = normalize_2d(amp)
	amp_shifted_norm = normalize_2d(amp_shifted)
	# make comparison table to compare prediction and frequency
	table = pd.concat([pd.DataFrame(freq),pd.DataFrame(amp_norm),pd.DataFrame(pha)],axis=1)
	table_shifted = pd.concat([pd.DataFrame(freq_shifted),pd.DataFrame(amp_shifted_norm),pd.DataFrame(pha_shifted)],axis=1)

	ret = pd.concat([table,table_shifted])
	amp = np.vstack([amp_norm,amp_shifted_norm])
	pha = np.vstack([pha,pha_shifted])
	return amp.reshape(amp.shape[0],amp.shape[1],1), pha.reshape(pha.shape[0],pha.shape[1],1), ret

# define the method of input process
def input_process_ExtMeasurement( ExtMeasurement ):
	dfs = []	
	data_arrays = []

	xAxisLen = ExtMeasurement.rawData["x"].shape[0]
	rawData = ExtMeasurement.rawData["iqSignal"][0]
	ampData = abs(rawData)
	phaseData = angle(rawData)


	for i in range(1):				 #There are only 1 file
		#read = pd.read_csv(file)
		if xAxisLen%50 != 0:							
			dfs.append(pd.DataFrame(read[0:(read.shape[0]-(read.shape[0]%50))].drop(['exported by'], axis=1).values.astype(float))) #[0:(read.shape[0]-(read.shape[0]%len))] make the length be the 50 times
		else:
			dfs.append(pd.DataFrame(read[0:read.shape[0]].drop(['exported by'], axis=1).values.astype(float))) #freq,Amp,Uphase,I,Q
								
		temp = []					 # There are 3 arrays in the temp : [Freq, Amp, Pha]
		for j in range(3):
			temp.append(np.array(dfs[i][j]))


		data_arrays.append(np.array(temp))			

	datas = np.array(data_arrays)
	# cut the file for len = 50
	shift = [0,25]
	shifted = []
	for l in shift:
		seperated = []
		for i in range(datas.shape[0]):																 # with the freq range	"4~5 ,..."
			temp = []
			for j in range(datas.shape[1]):															 # with the label "freq,Amp,Pha" 
				temp_ = []																	 
				for k in range(0,datas.shape[2]-50-l,50):
						
					temp_.append(np.array(datas[i][j][k+l:k+l+50]))					# seperate with length = len 
				temp.append(temp_)

			seperated.append(temp)
		shifted.append(seperated)
	shifted = np.array(shifted)

# extract amplitude. phase, frequency
	amp = shifted[0][0][1]
	amp_shifted = shifted[1][0][1]
	pha = shifted[0][0][2]
	pha_shifted = shifted[1][0][2]
	freq = shifted[0][0][0]	
	freq_shifted = shifted[1][0][0]

	freq = find_freq(freq)
	freq_shifted = find_freq(freq_shifted)

	# normalize amp
	amp_norm = normalize_2d(amp)
	amp_shifted_norm = normalize_2d(amp_shifted)
	# make comparison table to compare prediction and frequency
	table = pd.concat([pd.DataFrame(freq),pd.DataFrame(amp_norm),pd.DataFrame(pha)],axis=1)
	table_shifted = pd.concat([pd.DataFrame(freq_shifted),pd.DataFrame(amp_shifted_norm),pd.DataFrame(pha_shifted)],axis=1)

	ret = pd.concat([table,table_shifted])
	amp = np.vstack([amp_norm,amp_shifted_norm])
	pha = np.vstack([pha,pha_shifted])
	return amp.reshape(amp.shape[0],amp.shape[1],1), pha.reshape(pha.shape[0],pha.shape[1],1), ret


# define a function to sort according to the 'true' probability from the biggest to the smallest 
def prob_sort(amp_pred,pha_pred,true_amp,true_pha):
	amp = []
	pha = []
	if true_amp.shape[0] == 0:																		 # if its length is 0 then we cannot vstack the different size array together we should put the size all the same.
		amp.append([0,-1,1])
	else:
		for i in range(true_amp.shape[0]):
			amp.append([true_amp[i],amp_pred[true_amp[i]][1],1])	# true_amp = [idx_1,idx_2,.....], amp_pred = [prob_false , prob_true]

	if true_pha.shape[0] == 0:																		 # if its length is 0 then we cannot vstack the different size array together we should put the size all the same.
		amp.append([0,-1,2])
	else:
		for j in range(true_pha.shape[0]):
			pha.append([true_pha[j],pha_pred[true_pha[j]][1],2])

	amp = np.array(amp)
	pha = np.array(pha)
	mixed = np.vstack([amp,pha])	# mix to sort
	
	# sort by prob 
	sorted_mixed = np.array(sorted(mixed, key=lambda x:x[1], reverse=True))	# [1] stands for the probability 

	# delet the [a,-1,b]
	aux_idx = []
	for i in range(sorted_mixed.shape[0]):
		if sorted_mixed[i][1] == -1:
			aux_idx.append(i)
	
	sorted_mixed = np.delete(sorted_mixed,aux_idx,axis=0)

	
	return sorted_mixed

# define determin the prediction is the same peak or not >>> shift by 25 
# in given array the elements are the predicted True indexes, put the index in the compare table to check the value of amp/pha 
# because the index between non-shift & shifted is the (half length - 1) -> 'mid_index' , we can converse the shifted index to the non-shifted index by the mid_index
def detect_shift(true_amp,true_pha,amp_pred):
	mid_idx = (amp_pred.shape[0]/2)-1
	same_idx = []
	for i in range(0,true_amp.shape[0]-1,1):
		sample = true_amp[i]		 
		for j in range(i+1,true_amp.shape[0],1):
			target = true_amp[j]
			if abs(target - sample) == (mid_idx):		# length - 1 = index 
				same_idx.append(j)

	true_amp = np.delete(true_amp,same_idx)
	
	same_idx = []
	for i in range(0,true_pha.shape[0]-1,1):
		sample = true_pha[i]		 
		for j in range(i+1,true_pha.shape[0],1):
			target = true_pha[j]
			if abs(sample - target) == (mid_idx):
				same_idx.append(j)
	
	true_pha = np.delete(true_pha,same_idx)

	# converse the shifted to non-shifted index
	for i in range(true_amp.shape[0]):
		if true_amp[i] > mid_idx:
			true_amp[i] = true_amp[i] - mid_idx
	for j in range(true_pha.shape[0]):
		if true_pha[j] > mid_idx:
			true_pha[j] = true_pha[j] - mid_idx

	return true_amp,true_pha

# define output_process 
def output_process(amp_pred,pha_pred,comparison):		 # there should be n peaks
	true_amp = []
	true_pha = []
	for i in range(amp_pred.shape[0]):		
		if amp_pred[i][0] < amp_pred[i][1]:				 # prediction is True
			true_amp.append(i)						# add the number into the true_amp
		elif (amp_pred[i][0]-amp_pred[i][1])<=0.05:	# prediction is False but with a very close differences
			true_amp.append(i)
		else:
			pass
	true_amp = np.array(true_amp) 

	for j in range(pha_pred.shape[0]):		
		if pha_pred[j][0] < pha_pred[j][1]:				 # prediction is True
			true_pha.append(j)						# add the number into the true_amp
		elif (pha_pred[j][0]-pha_pred[j][1])<=0.05:	# prediction is False but with a very close differences
			true_pha.append(j)
		else:
			pass
	true_pha = np.array(true_pha)
	
	# check is it the same peak or not
	true_amp,true_pha = detect_shift(true_amp,true_pha,amp_pred)

	# pick the both model prediction
	true = []
	overlap_index_amp = []
	overlap_index_pha = []
	for i in range(true_amp.shape[0]):
		for j in range(true_pha.shape[0]):
			if true_amp[i] == true_pha[j]:
				
				true.append([true_amp[i],comparison[true_amp[i]][0],comparison[true_amp[i]][1]])		# if AMP & PHA predict the same result, append the freq range [0]~[1]
				overlap_index_amp.append(i)
				overlap_index_pha.append(j)				 # take a note for the overlap index in order to delet from the original array

	true_amp = np.delete(true_amp,overlap_index_amp)
	true_pha = np.delete(true_pha,overlap_index_pha)				 #delete the overlap elements
	true = np.array(true)
	sum = []
	for i in range(true.shape[0]):
		idx = int(true[i][0])
		if amp_pred[idx][1] > amp_pred[idx][0]:
			if pha_pred[idx][1] > pha_pred[idx][0]:
				sum.append([idx,amp_pred[idx][1] + pha_pred[idx][1]])
			else:
				sum.append([idx,amp_pred[idx][1] + pha_pred[idx][0]])
		else:
			if pha_pred[idx][1] > pha_pred[idx][0]:
				sum.append([idx,amp_pred[idx][0] + pha_pred[idx][1]])
			else:
				sum.append([idx,amp_pred[idx][0] + pha_pred[idx][0]])
	sum = np.array(sorted(np.array(sum), key=lambda x:x[1], reverse=True))
	
	out_true = []
	for i in range(sum.shape[0]):
		for j in range(true.shape[0]):
			if true[j][0] == sum[i][0]:
				out_true.append(true[j])
	true = np.array(out_true)

	alt_idx = prob_sort(amp_pred,pha_pred,true_amp,true_pha)	# alt_idx = [idx , prob , 1 or 2] (1 for amp ; 2 for pha)
	alt = []
	for k in range(alt_idx.shape[0]):
		idx = int(alt_idx[k][0])
		alt.append([idx,comparison[idx][0],comparison[idx][1],alt_idx[k][2]])
	
	return true, np.array(alt)

# define a method to determine the peak in the window is(1) whole or not(0).
# the following try to calculate the slope between each two points	
# if the peak in the window is the whole peak the slope will change rapidly (the diff. between slope_max & slope_min < 15 points)
# if the peak in the window is a part of the whole peak the slope will change slowly (the diff. between slope_max & slope_min > 15 points)	
# and at the mid-point is just the peak location
def peak_info(target_df):
	target_ary = np.array(target_df)
	
	slope = []
	for j in range(0,target_ary.shape[0]-1):
		slope.append(target_ary[j+1]-target_ary[j])
	
	max_idx = slope.index(max(slope))							 # <<<< assume the peak tip should always be in the prediction	window
	min_idx = slope.index(min(slope))					 
	distance = abs(max_idx - min_idx)
	
	if distance < 15:			 # determine whole peak or not 
		if max_idx > min_idx :			# find the location of the tip of the peak
			loc_idx = min_idx + int(distance/2) + 1
			return loc_idx,distance
		else:
			loc_idx = max_idx + int(distance/2) + 1
			return loc_idx,distance
	else:
		if max_idx > min_idx :
			loc_idx = min_idx + int(distance/2) + 1
			return loc_idx,distance*2
		else:
			loc_idx = max_idx + int(distance/2) + 1
			return loc_idx,distance*2


# define the output plot 
def true_alt_info(true,alt,origin_fig):
	zone_true = []
	for i in range(true.shape[0]):
	# contract the values between the given frequency range 
		target_pha_df = origin_fig[origin_fig["<b>frequency(GHz)</b>"].between(true[i][1],true[i][2])]['UPhase']	 # plot true[1]
		target_amp_df = origin_fig[origin_fig["<b>frequency(GHz)</b>"].between(true[i][1],true[i][2])]['Amplitude'] 
		target_pha_freq_df = origin_fig[origin_fig["<b>frequency(GHz)</b>"].between(true[i][1],true[i][2])]['<b>frequency(GHz)</b>']
		target = pd.concat([target_pha_freq_df,target_amp_df,target_pha_df],axis=1)

		loc_idx_pha,distance_pha = peak_info(target_pha_df)
		loc_idx_amp,distance_amp = peak_info(target_amp_df)

		tip_freq_pha = np.array(target)[loc_idx_pha][0]
		tip_freq_amp = np.array(target)[loc_idx_amp][0]
		tip_idx_pha = origin_fig.index[origin_fig["<b>frequency(GHz)</b>"] == tip_freq_pha][0]
		tip_idx_amp = origin_fig.index[origin_fig["<b>frequency(GHz)</b>"] == tip_freq_amp][0]


		amp_df = pd.DataFrame(np.array(origin_fig.iloc[tip_idx_amp-(distance_amp*8):tip_idx_amp+(distance_amp*8),:3]),columns=['Frequency(GHz)','Amplitude','UPhase'])
		pha_df = pd.DataFrame(np.array(origin_fig.iloc[tip_idx_pha-(distance_pha*8):tip_idx_pha+(distance_pha*8),:3]),columns=['Frequency(GHz)','Amplitude','UPhase'])


		amp_head = np.array(amp_df['Frequency(GHz)'])[0]
		amp_tail = np.array(amp_df['Frequency(GHz)'])[-1]
		pha_head = np.array(pha_df['Frequency(GHz)'])[0]
		pha_tail = np.array(pha_df['Frequency(GHz)'])[-1]

		if amp_head <= pha_head :
			head = amp_head
		else:
			head = pha_head
		if amp_tail >= pha_tail :
			tail = amp_tail
		else:
			tail = pha_tail

		zone_true.append([i+1,head,tail,0])

		zone = np.vstack([np.array(zone_true),alt])

		out = []
		for i in range(zone.shape[0]):
			out.append([i+1,zone[i][1],zone[i][2],zone[i][3]])
	return np.array(out)